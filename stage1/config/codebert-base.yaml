data:
  notebooks:
  - ../resources/ai4code/train_cleaned
  - ../resources/codeparrot/train_cleaned
  - ../resources/kgtorrent/train_cleaned
  min_characters: 5
  max_length: 128
  num_workers: 6

model:
  pretrained_model_name_or_path: microsoft/codebert-base
  attention_probs_dropout_prob: 0.1
  hidden_dropout_prob: 0.1

optim:
  optimizer:
    lr: 2e-5
    betas: [0.9, 0.98]
    eps: 1e-6
    weight_decay: 0.01
  scheduler:
    name: linear
    num_warmup_steps: 10000
    num_training_steps: 150000
  loss_mlm_weight: 0.1

train:
  batch_size: 128
  gradient_clip_val: 0.0
  accumulate_grad_batches: 1
  validation_interval: 1
  log_every_n_steps: 50
